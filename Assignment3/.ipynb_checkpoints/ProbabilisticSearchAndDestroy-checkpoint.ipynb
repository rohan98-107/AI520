{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Search and Destroy\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Rohan Rele (rsr132)\n",
    "- Aakash Raman (abr103)\n",
    "- Alex Eng (ame136)\n",
    "- Adarsh Patel (aap237)\n",
    "\n",
    "This project was completed for Professor Wes Cowan's Fall 2019 offering of the CS 520: Intro to Artificial Intelligence course, taught at Rutgers University, New Brunswick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we consider a two-dimensional map of cells in which one cell is randomly designated as the target. The location of the target is not known to any solving agent. Therefore, the problem is to devise an agent which can effectively query the landscape of cells, contribute towards its knowledge base based on observations, and ultimately find the target in the **minimal number of queries.**\n",
    "\n",
    "The knowledge base itself will contain probabilistic knowledge, i.e. \n",
    "\n",
    "$$\\text{Belief}[\\text{Cell}_i] = P(\\text{Target in Cell}_i|  \\text{Observations through time } t)$$ \n",
    "\n",
    "For every cell, this is the probability that a given cell contains the target given the existing knowledge base. Initially, as the agent has no prior knowledge about the map, the belief for each cell is $\\frac{1}{dim^2}$.\n",
    "\n",
    "Each cell also contains a terrain type which corresponds to the probability that a query will return a false negative, i.e.\n",
    "\n",
    "$$P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)$$\n",
    "\n",
    "which is $0.1$ for **flat** terrain cells, $0.3$ for **hilly** terrain cells, $0.7$ for **forested** terrain cells, and $0.9$ for cells whose terrain is a maze of **caves.**\n",
    "\n",
    "We assume that for any given map, each cell is assigned the flat terrain type with probability $0.2$, the hilly terrain type with probability $0.3$, the forested terrain type with probability $0.3$, and the caves terrain type with probability $0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landscape\n",
    "\n",
    "We implement the landscape as a class, which has the following fields:\n",
    "\n",
    "- `dim` (int): the dimension of the $dim$ by $dim$ map\n",
    "- `landscape` (2D list) of `landCell` objects, each of which tracks:\n",
    "    - `target` (int): `PRESENT = 1` if this cell is the target, or `ABSENT = 0` otherwise\n",
    "    - `terrain` (int): `FLAT = 0.1` if this cell has flat terrain, `HILLY = 0.3`, `FOREST = 0.7`, or `MAZE = 0.9`, etc.\n",
    "- `target_x` (int): the x-coordinate of the target cell\n",
    "- `target_y` (int): the y-coordinate of the target cell\n",
    "\n",
    "A landscape is initialized with non-target cells that are assigned terrain types based on the probabilities previously described. It then randomly selects one cell to be the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class landscape:\n",
    "\n",
    "    dim = 0\n",
    "    landscape = [[]]\n",
    "    target_x = 0\n",
    "    target_y = 0\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.landscape = [[landCell() for _ in range(self.dim)] for _ in range(self.dim)]\n",
    "\n",
    "        target_x = random.randint(0, dim - 1)\n",
    "        target_y = random.randint(0, dim - 1)\n",
    "        self.landscape[target_x][target_y].target = PRESENT\n",
    "        self.target_x = target_x\n",
    "        self.target_y = target_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Landscape.py`.\n",
    "\n",
    "The `landCell` object is also defined in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class landCell:\n",
    "\n",
    "    def __init__(self):\n",
    "        x = random.randint(1, 100)\n",
    "        self.target = ABSENT\n",
    "        if x <= 20:\n",
    "            self.terrain = FLAT\n",
    "        elif 20 < x <= 50:\n",
    "            self.terrain = HILLY\n",
    "        elif 50 < x <= 80:\n",
    "            self.terrain = FOREST\n",
    "        else:\n",
    "            self.terrain = MAZE\n",
    "\n",
    "    def getTerrain(self):\n",
    "        return self.terrain\n",
    "\n",
    "    def isTarget(self):\n",
    "        return (self.target==PRESENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Cell.py`.\n",
    "\n",
    "For example, an initialized $dim = 50$ landscape may look like this:\n",
    "\n",
    "![Blank Landscape](./imgs/landscape_blankTest.png)\n",
    "\n",
    "where the target is located at (40, 48)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the agent as a class, which has the following fields:\n",
    "\n",
    "- `knowledge` (2D list) of `agentCell` objects, each of which tracks:\n",
    "    - `belief` (float): the probability that a given cell contains the target, as described above; initially $1/{dim}^2$\n",
    "    - `status` (boolean): either `VISITED = True` or `UNVISITED = False` depending on whether or not the cell has been queried previously; initially `False`\n",
    "- `rule` (int): either 1 or 2, corresponding to the two probability rules described below\n",
    "- `num_actions` (int): the number of actions, whether queries or movements (in the later case of a movement-restricted agent), executed so far; initially 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent:\n",
    "    num_actions = 0\n",
    "\n",
    "    def __init__(self, landscape, rule):\n",
    "        self.ls = landscape\n",
    "        d = self.ls.dim\n",
    "\n",
    "        if rule == 1 or rule == 2:\n",
    "            self.rule = rule\n",
    "        else:\n",
    "            print(\"Invalid rule, set to 1 by default\")\n",
    "            self.rule = 1\n",
    "\n",
    "        self.knowledge = [[agentCell() for j in range(d)] for i in range(d)]\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                self.knowledge[i][j].setBelief(1/(d**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Agent.py`.\n",
    "\n",
    "The `agentCell` object is also defined in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agentCell:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.belief = 0\n",
    "        self.status = UNVISITED\n",
    "\n",
    "    def getBelief(self):\n",
    "        return self.belief\n",
    "\n",
    "    def getStatus(self):\n",
    "        return self.status\n",
    "\n",
    "    def setBelief(self,belief):\n",
    "        self.belief = belief\n",
    "\n",
    "    def setStatus(self,status):\n",
    "        self.status = status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Cell.py`.\n",
    "\n",
    "For example, an initialized agent knowledge base with $dim = 50$ landscape may look like this:\n",
    "\n",
    "![Blank Beliefs](./imgs/belief_blankTest.png)\n",
    "\n",
    "where each cell has initial belief $\\frac{1}{50^2} = 0.0004$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agent` class also has the following methods (non-exhaustive list):\n",
    "\n",
    "- `searchCell(cell)` (boolean): query a `landCell` object. If it is not the target, return `False`. If it is the target, then only return `True` with probability $p = 1 - P(\\text{false negative})$, where the false negative probability depends on that cell's terrain type as described previously. Otherwise, return `False`. \n",
    "\n",
    "**Note:** In either case, the number of actions taken by the agent is incremented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchCell(self,cell): #search a landCell\n",
    "    self.num_actions += 1\n",
    "    \n",
    "    if not cell.isTarget():\n",
    "        return False\n",
    "    else:\n",
    "        p = 1 - cell.getTerrain()\n",
    "        if random.uniform(0, 1) < p:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `getVisited()` (list): return a list of all (x,y) coordinates which the agent has already queried at a given point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVisited(self):\n",
    "    n = self.ls.dim\n",
    "    coords = []\n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            if self.knowledge[x][y].getStatus():\n",
    "                coords.append((x,y))\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the belief state\n",
    "\n",
    "We require a method to update the belief state given the results of a query. There are two cases: \n",
    "\n",
    "1. A query of a cell found the target, in which case the belief for this cell is set to 1, and the beliefs for all other cells are set to 0.\n",
    "\n",
    "2. A query of a cell did not find the target, in which case the belief for this cell must be adjusted considering the probability that the query returned a false negative.\n",
    "\n",
    "The latter case considers the probability \n",
    "\n",
    "$$P(\\text{Target in Cell}_i | \\text{Observations}_t \\land \\text{Failure in Cell}_j)$$\n",
    "\n",
    "and relies on the probabilistic knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $H := \\{\\text{Target in Cell}_i\\}$ and $E := \\{\\text{Target not found if we queried every cell}\\}$. \n",
    "\n",
    "Then we want $P(H|E)$, or the probability that the target is in a cell given we have not found the target in any of our queries. We would like to compute this upon a failed query of a cell and accept this quantity as that cell's new belief.\n",
    "\n",
    "By **Bayes' theorem,** this quantity is:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H)P(H)}{P(E)}$$\n",
    "\n",
    "Observe that $P(E|H)$ is the probability that the target is not found given the target is in the cell, which is exactly the false negative probability described above per terrain type. And $P(H)$ is exactly the agent's belief for that cell in the previous time step.\n",
    "\n",
    "One can see that observing a failed query for a given cell will decrease our belief that this cell contains the target, but this decrease is scaled by the possibility of false negatives.\n",
    "\n",
    "$P(E)$ is calculated with the following function: \n",
    "\n",
    "$$P(E) = \\sum_{i \\text{ visited}} P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i) + \\sum_{j \\text{ unvisited}} P(\\text{Target not in Cell}_j)$$\n",
    "\n",
    "That is, it is the probability that some queried cell was a false negative and that the unqueried cells do not contain the target. In this situation, querying all remaining cells would not lead to us finding the target.\n",
    "\n",
    "Finally, once a queried cell is updated, we must update the rest of the knowledge base. \n",
    "\n",
    "Let $R_i = |{\\text{new belief of Cell}_i} - {\\text{old belief of Cell}_i}|$, or the difference between the new and old beliefs of the queried cell.\n",
    "\n",
    "Then for all remaining cells $j$, use the following update formula: \n",
    "\n",
    "$$\\text{Belief}^{t+1}_j = \\text{Belief}^t_j + \\frac{\\text{Belief}^t_j * R_i}{1 - R_i}$$\n",
    "\n",
    "This, in a sense, scales the previous belief by how much our query impacted the belief of the queried cell. One can see how failed queries will increase the beliefs of all other cells per iteration, although this increase may be marginal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Based on the intuition above, the implementation of a belief update is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBelief(self,x,y):\n",
    "    if self.searchCell(self.ls.landscape[x][y]):\n",
    "        for i in range(self.ls.dim):\n",
    "            for j in range(self.ls.dim):\n",
    "                self.knowledge[i][j].setBelief(0)\n",
    "        self.knowledge[x][y].setBelief(1)\n",
    "    else:\n",
    "        #P(H|E) = P(E|H)P(H)/P(E)\n",
    "        #H: Target in cell\n",
    "        #E: Target not found\n",
    "        curr_belief = self.knowledge[x][y].getBelief()\n",
    "        num = self.ls.landscape[x][y].getTerrain()*curr_belief\n",
    "        denom = self.probNotFound()\n",
    "        remainder = abs(curr_belief - (num/denom))\n",
    "        self.knowledge[x][y].setBelief(num/denom)\n",
    "        for i in range(self.ls.dim):\n",
    "            for j in range(self.ls.dim):\n",
    "                if i == x and j == y:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp = self.knowledge[i][j].getBelief()\n",
    "                    self.knowledge[i][j].setBelief(temp + (temp*remainder)/(1-remainder))\n",
    "\n",
    "    return self.knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a new belief for a specified cell and updates the beliefs about the rest of the map, as described earlier. It relies on the function `probNotFound` which computes $P(H|E)$ exactly as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probNotFound(self):\n",
    "    n = self.ls.dim\n",
    "    res = 0\n",
    "    coords = self.getVisited()\n",
    "    res = (n**2 - len(coords))/(n**2)\n",
    "    for coord in coords:\n",
    "        res += (self.ls.landscape[coord].getTerrain())*(self.knowledge[coord].getBelief())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Agent.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent search strategies\n",
    "\n",
    "Armed with this `updateBelief` function, we need to define how the agent will choose cells to query in order to search maps. We consider two rules for which cell the agent should query next:\n",
    "\n",
    "1. Query the cell with the highest belief, i.e. the probability that **the target is in that cell.**\n",
    "\n",
    "2. Query the cell with the highest probability that **the target will be found in such a query.**\n",
    "\n",
    "We implement both probability rules, and then use either of them to implement the agent's search algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 1: Probability that the target is in a given cell\n",
    "\n",
    "This is based on the same $P(H|E)$ computed above. Upon each failed query, we update the entire knowledge base of beliefs as described above, and then we visit the cell with the highest belief. Its implementation is described above via `updateBelief`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 2: Probability that the target will be found, if a given cell is searched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic intuition\n",
    "\n",
    "Observe that this probability is different from $\\text{Belief}_i$. It must consider the impact of the terrain's interference with queries, i.e. potential false negatives. We want the following probability:\n",
    "\n",
    "$$P(F) := P(\\text{Target found in Cell}_i | \\text{Observations}_t)$$\n",
    "\n",
    "which is equal to:\n",
    "\n",
    "$$(1 - P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)) * P(\\text{Target is in Cell}_i)$$\n",
    "\n",
    "Note that $P(\\text{Target is in Cell}_i)$ is exactly $P(H)$ from before, and $P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)$ is determined by the terrain type of $\\text{Cell}_i$, so we can easily compute $P(F)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The probability that the target will be found at a given cell if it is searched is computed by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probFound(self,x,y):\n",
    "        return (1-self.ls.landscape[x][y].getTerrain())*self.knowledge[x][y].getBelief()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent search implementation for both rules\n",
    "\n",
    "We drive the above probability-calculating and belief update functions with the below methods in the `agent` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLikCell(self):\n",
    "    if self.rule == 1:\n",
    "        #get max i for P(Target in Cell i)\n",
    "        belief = np.array([[self.knowledge[i][j].getBelief() for j in range(self.ls.dim)] for i in range(self.ls.dim)])\n",
    "        return np.unravel_index(belief.argmax(),belief.shape)\n",
    "    else:\n",
    "        #get max i for P(Target FOUND in Cell i)\n",
    "        belief = [[self.knowledge[i][j].getBelief()*(1-self.ls.landscape[i][j].getTerrain()) for j in range(self.ls.dim)] for i in range(self.ls.dim)]\n",
    "        belief = np.array(belief)\n",
    "        return np.unravel_index(belief.argmax(),belief.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will find the cell with maximum probability for either rule:\n",
    "\n",
    "1. Return the cell coordinates with the highest Rule 1 probability, i.e. belief.\n",
    "2. Return the cell coordinates with the highest Rule 2 probability, i.e. the equation in `probFound` above.\n",
    "\n",
    "In either case, ties between multiple maximum-probability cells are broken arbitrarily.\n",
    "\n",
    "Finally, the driver code which will repeat belief updates and getting the maximum-probability cell is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTarget(self):\n",
    "    i = random.randint(0, self.ls.dim-1); j = random.randint(0, self.ls.dim-1)\n",
    "    while not self.searchCell(self.ls.landscape[i][j]):\n",
    "        self.knowledge = self.updateBelief(i,j)\n",
    "        i,j = self.getMaxLikCell()\n",
    "    return (i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will randomly select a cell to query for the first iteration. Then, for subsequent iterations, it will query the cell with the highest-probability (based on either rule), and update all beliefs along the way. It terminates once the target is found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison between both rules\n",
    "\n",
    "For all comparisons listed below between the two probability rules prioritized in `getMaxLikCell`, we run trials on map(s) of $dim = 50$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated trials over the same landscape\n",
    "\n",
    "For a fixed landscape, we run $n=200$ trials of Rule 1 agents and Rule 2 agents solving the same map, and we record the number of actions taken for each agent and trial. Note that for each trial, we also reset the location of the target to a new and different location, chosen uniformly at random via the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetTarget(self):\n",
    "    x = self.target_x; y = self.target_y\n",
    "    self.landscape[x][y].target = ABSENT\n",
    "    \n",
    "    new_targ_coords = list(set([(x,y) for x in range(self.dim) for y in range(self.dim)]).difference({(x,y)}))\n",
    "    \n",
    "    new_target = random.choice(new_targ_coords)\n",
    "    self.target_x = new_target[0]\n",
    "    self.target_y = new_target[1]\n",
    "    self.landscape[self.target_x][self.target_y].target = PRESENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the following randomly-generated landscape, where the target is **initially** at (41, 46).\n",
    "\n",
    "![Fixed Landscape Rule One v. Two Trials](./imgs/landscape_ruleOneTwoComparison.png)\n",
    "\n",
    "The comparison data generated is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RuleOne</th>\n",
       "      <td>4193</td>\n",
       "      <td>1535</td>\n",
       "      <td>1617</td>\n",
       "      <td>4949</td>\n",
       "      <td>1865</td>\n",
       "      <td>583</td>\n",
       "      <td>647</td>\n",
       "      <td>1549</td>\n",
       "      <td>3891</td>\n",
       "      <td>2623</td>\n",
       "      <td>...</td>\n",
       "      <td>4623</td>\n",
       "      <td>741</td>\n",
       "      <td>213</td>\n",
       "      <td>2001</td>\n",
       "      <td>3489</td>\n",
       "      <td>4207</td>\n",
       "      <td>2513</td>\n",
       "      <td>2145</td>\n",
       "      <td>2515</td>\n",
       "      <td>3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleTwo</th>\n",
       "      <td>3825</td>\n",
       "      <td>297</td>\n",
       "      <td>1509</td>\n",
       "      <td>4045</td>\n",
       "      <td>3145</td>\n",
       "      <td>1173</td>\n",
       "      <td>121</td>\n",
       "      <td>6069</td>\n",
       "      <td>5247</td>\n",
       "      <td>545</td>\n",
       "      <td>...</td>\n",
       "      <td>17261</td>\n",
       "      <td>145</td>\n",
       "      <td>1059</td>\n",
       "      <td>25745</td>\n",
       "      <td>3599</td>\n",
       "      <td>2319</td>\n",
       "      <td>517</td>\n",
       "      <td>439</td>\n",
       "      <td>1759</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5    6     7     8     9    ...  \\\n",
       "RuleOne  4193  1535  1617  4949  1865   583  647  1549  3891  2623  ...   \n",
       "RuleTwo  3825   297  1509  4045  3145  1173  121  6069  5247   545  ...   \n",
       "\n",
       "           190  191   192    193   194   195   196   197   198   199  \n",
       "RuleOne   4623  741   213   2001  3489  4207  2513  2145  2515  3265  \n",
       "RuleTwo  17261  145  1059  25745  3599  2319   517   439  1759   687  \n",
       "\n",
       "[2 rows x 200 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fixed_ruleOneTwoComp_df = pd.read_csv('./data/fixed_map_comparison_ruleOneTwo.csv')[['RuleOne', 'RuleTwo']]\n",
    "fixed_ruleOneTwoComp_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above trial-by-trial data on the number of searches required for the agents (using rules 1 or 2) to find the target can be visualized via the following scatter plot:\n",
    "\n",
    "![Rules 1-2 Comparison by Trials, Scatter](./imgs/fixed_map_comparison_ruleOneTwoScatter.png)\n",
    "\n",
    "It appears that the agent using Rule 1 requires a higher number of searches to find the target. But this pattern is not immediately clear. To mediate this, we consider the quantity:\n",
    "\n",
    "$$\\text{Diff} = \\text{Number of searches}_{\\text{Rule1}} - \\text{Number of searches}_{\\text{Rule2}}$$\n",
    "\n",
    "![Rules 1-2 Difference by Trials, Plot](./imgs/fixed_map_comparison_ruleOneTwoDiff.png)\n",
    "\n",
    "![Rules 1-2 Difference by Trials, Box](./imgs/fixed_map_comparison_ruleOneTwoDiffBox.png)\n",
    "\n",
    "The above images show that the difference between the number of searches required following rules 1 and 2 has high spread. The following 1-variable statistics describe the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>200.0</td>\n",
       "      <td>426.55</td>\n",
       "      <td>8418.856089</td>\n",
       "      <td>-49320.0</td>\n",
       "      <td>-890.5</td>\n",
       "      <td>739.0</td>\n",
       "      <td>2578.5</td>\n",
       "      <td>30422.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count    mean          std      min    25%    50%     75%      max\n",
       "diff  200.0  426.55  8418.856089 -49320.0 -890.5  739.0  2578.5  30422.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixedmap_1varstats = pd.read_csv('./data/fixedmap_1varstats.csv', index_col=0)\n",
    "fixedmap_1varstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, for a fixed map, it appears that **the agent using Rule 2** outperforms the agent using Rule 1 in terms of, on average, **427 fewer searches required to find the target.** However, the large variance visualized above strongly motivates repeated trials over multiple randomly-generated maps in order to see if this pattern holds in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated trials over multiple landscapes\n",
    "\n",
    "We conduct similar trials to compare both agents for $N = 50$ distinct and randomly generated maps. For each map and agent, we record the average number of actions taken to find the target over $n = 30$ trials. As above, we reset the target to a random new location in between each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RuleOne</th>\n",
       "      <td>6239.666667</td>\n",
       "      <td>8238.2</td>\n",
       "      <td>7995.200000</td>\n",
       "      <td>4642.600000</td>\n",
       "      <td>5201.333333</td>\n",
       "      <td>6096.200000</td>\n",
       "      <td>5929.8</td>\n",
       "      <td>3793.733333</td>\n",
       "      <td>6416.133333</td>\n",
       "      <td>4689.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>4645.466667</td>\n",
       "      <td>5928.066667</td>\n",
       "      <td>6189.0</td>\n",
       "      <td>3903.866667</td>\n",
       "      <td>6836.933333</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>4923.266667</td>\n",
       "      <td>7069.466667</td>\n",
       "      <td>8294.866667</td>\n",
       "      <td>7375.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleTwo</th>\n",
       "      <td>3687.333333</td>\n",
       "      <td>7271.0</td>\n",
       "      <td>6089.666667</td>\n",
       "      <td>4928.133333</td>\n",
       "      <td>8382.600000</td>\n",
       "      <td>6516.933333</td>\n",
       "      <td>5877.8</td>\n",
       "      <td>4493.466667</td>\n",
       "      <td>7009.933333</td>\n",
       "      <td>3859.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>5404.133333</td>\n",
       "      <td>6142.333333</td>\n",
       "      <td>4896.2</td>\n",
       "      <td>6497.600000</td>\n",
       "      <td>7608.733333</td>\n",
       "      <td>5126.333333</td>\n",
       "      <td>5827.266667</td>\n",
       "      <td>7152.266667</td>\n",
       "      <td>9738.533333</td>\n",
       "      <td>7034.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1            2            3            4   \\\n",
       "RuleOne  6239.666667  8238.2  7995.200000  4642.600000  5201.333333   \n",
       "RuleTwo  3687.333333  7271.0  6089.666667  4928.133333  8382.600000   \n",
       "\n",
       "                  5       6            7            8            9   ...  \\\n",
       "RuleOne  6096.200000  5929.8  3793.733333  6416.133333  4689.800000  ...   \n",
       "RuleTwo  6516.933333  5877.8  4493.466667  7009.933333  3859.933333  ...   \n",
       "\n",
       "                  40           41      42           43           44  \\\n",
       "RuleOne  4645.466667  5928.066667  6189.0  3903.866667  6836.933333   \n",
       "RuleTwo  5404.133333  6142.333333  4896.2  6497.600000  7608.733333   \n",
       "\n",
       "                  45           46           47           48           49  \n",
       "RuleOne  4990.000000  4923.266667  7069.466667  8294.866667  7375.866667  \n",
       "RuleTwo  5126.333333  5827.266667  7152.266667  9738.533333  7034.200000  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_ruleOneTwoComp_df = pd.read_csv('./data/multimap_comparison_ruleOneTwo.csv')[['RuleOne', 'RuleTwo']]\n",
    "multi_ruleOneTwoComp_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rules 1-2 Comparison by Trials, Multi, Scatter](./imgs/multi_map_comparison_ruleOneTwoScatter.png)\n",
    "\n",
    "![Rules 1-2 Difference by Trials, Multi, Plot](./imgs/multi_map_comparison_ruleOneTwoDiff.png)\n",
    "\n",
    "![Rules 1-2 Difference by Trials, Multi, Box](./imgs/multi_map_comparison_ruleOneTwoDiffBox.png)\n",
    "\n",
    "As before, the difference distribution shown above has quite a large spread. The distribution can be described by the following one-variable descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>50.0</td>\n",
       "      <td>259.573333</td>\n",
       "      <td>1722.672219</td>\n",
       "      <td>-3181.266667</td>\n",
       "      <td>-787.8</td>\n",
       "      <td>26.233333</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>4715.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count        mean          std          min    25%        50%     75%  \\\n",
       "diff   50.0  259.573333  1722.672219 -3181.266667 -787.8  26.233333  1290.0   \n",
       "\n",
       "              max  \n",
       "diff  4715.533333  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimap_1varstats = pd.read_csv('./data/multimap_1varstats.csv', index_col=0)\n",
    "multimap_1varstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that over multiple maps, **rule two** still outperforms rule one by ways of, on average, **260 fewer searches required to find the target.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "This makes intuitive sense, because rule two prioritizes a more realistic goal: *finding* the target versus trying to ordain where the target is. In a sense, the two rules are related, but rule two takes more directly into account the possibility of false negatives in a query. Instead of prioritizing where the target is, but possibly still getting a false negative in response, the rule two-prioritizing agent focuses on the most revealing queries. This is more \"intelligent\" in the sense that the agent's queries are more effective in driving belief updates, and this yields a lower number of searches required to find the target.\n",
    "\n",
    "Of course, these data does not seem like a decisive statistical victory for rule two. Accounting for multiple maps has reduced the standard deviation in the difference distribution from 8418 to 1722, but we see that a few outliers still have a pronounced effect on the distributions described above. After running trials on multiple maps, we do see that at best rule two outperforms rule one by 4715 fewer searches, and at worst rule one outperforms rule two by 3181 fewer searches; one might say that in both extreme worst case scenarios, rule two still prevails.\n",
    "\n",
    "But even though we hold maps fixed over repeated trials, variations in the data are naturally likely a result of:\n",
    "\n",
    "- Randomly selecting a first cell to query\n",
    "- Probabalistic revealing of false negatives\n",
    "\n",
    "As expected from the problem statement, every trial for the same map will vary in terms of how the agent will solve, which sequence of cells to query, etc. because the environment is probabilistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted agent movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 3: Utility and decision-making strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison with unrestricted movement via rules 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A drunk man"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A moving target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider a target which is not static in that:\n",
    "\n",
    "1. Upon every failed query, the target moves to one of its neighbors at random.\n",
    "2. Upon moving to one of its neighbors, some sensor returns an observation of terrain type (\"FLAT\" , \"HILLY\", etc.). However, the sensor is broken, so it returns some type that the new target is **not,** at random. \n",
    "\n",
    "For example, if we query a cell and do not find the target, and we get the new observation \"HILLY\", then we know that the target is now in a cell which is either \"FLAT\", \"FOREST\", or \"MAZE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Due to the object-oriented nature of our `Landscape` class, the target can easily be moved.\n",
    "\n",
    "The below code moves the target to one of its neighbors at random, and returns a terrain type the new target is not, at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveTarget(self):\n",
    "    x = self.target_x; y = self.target_y\n",
    "    self.landscape[x][y].target = ABSENT\n",
    "\n",
    "    nbrs = []\n",
    "    for dx, dy in dirs:\n",
    "        if 0 <= x + dx < self.dim and 0 <= y + dy < self.dim:\n",
    "            nbrs.append((x + dx, y + dy))\n",
    "\n",
    "    new_nbr = random.choice(nbrs)\n",
    "    self.target_x = new_nbr[0]; self.target_y = new_nbr[1]\n",
    "    self.landscape[self.target_x][self.target_y].target = PRESENT\n",
    "\n",
    "    terrains = {FLAT, HILLY, FOREST, MAZE}\n",
    "    new_terrain = {(self.landscape[self.target_x][self.target_y]).terrain}\n",
    "    return random.choice(list(terrains.difference(new_terrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "With a moving target, our first problem that arrives is that we have no true knowledge base of where the target will move after each iteration. In our stationary target search, there is an eventual end where we will find the target since it must exist in one of the squares of the grid. So in the worst case scenario it will take dim x dim searches to find the target. In a moving target scenario, this is not the case. There is a possibility that the target will never be found. \n",
    "\n",
    "To deal with this problem, we are provided with the information of the tracker. The tracker tells us with 100% assurance what terrain the target will not be in. So there is a 1/3 likeliness it exists in either of the other three terrains. With this information we can knock out 1/4 of the cells (this isn’t always 1/4, it depends on the random allocation according to the given probabilities). After this, we are also provided with the information as to where the target moved next since it only moves to its neighbors. \n",
    "\n",
    "At the base step, we are provided with a matrix that has 1/(total cells) probability in each cell. After making our first random guess, we can update the table according to our original strategy of obtaining probabilities. Now, we have the probabilities of each of the given cells according to the probabilities we attained through our normal means using Bayes Theorem. But now, we will use the information we receive from the tracker to remove cells of the terrain that the tracker reported since we know for certain they do not contain the target. Now, we have a reduced cell matrix. We choose the cell with the highest probability of containing the cell. \n",
    "\n",
    "Now, after our first guess reports a failed search - the target has moved. We are told that the target has moved to a neighbor of its previous cell. Since we are not sure where the target was, we cannot assume its neighbors. But what we can do is look into the neighbors of the previous cell and lower some of their probabilities depending on if they have neighbors from the opposite side or not. For example, if the cell is neighbors with a corner cell then you can lower the probability of both the cell and its neighbor since there is no other way of reaching that cell other than through the suspected target cell. \n",
    "\n",
    "A lot of this information that we now have access to is useful in the sense we are better off with this information than not and we can leverage the information to find a certain target faster. But, I am not sure how much better the tracker information really is compared to not having it. There isn’t too much use into the tracker since we can never truly be sure where the target is so we must make many assumptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A moving target AND an agent with restricted movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
