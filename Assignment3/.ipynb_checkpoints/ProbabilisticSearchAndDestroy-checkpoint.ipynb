{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Search and Destroy\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Rohan Rele (rsr132)\n",
    "- Aakash Raman (abr103)\n",
    "- Alex Eng (ame136)\n",
    "- Adarsh Patel (aap237)\n",
    "\n",
    "This project was completed for Professor Wes Cowan's Fall 2019 offering of the CS 520: Intro to Artificial Intelligence course, taught at Rutgers University, New Brunswick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we consider a two-dimensional map of cells in which one cell is randomly designated as the target. The location of the target is not known to any solving agent. Therefore, the problem is to devise an agent which can effectively query the landscape of cells, contribute towards its knowledge base based on observations, and ultimately find the target in the **minimal number of queries.**\n",
    "\n",
    "The knowledge base itself will contain probabilistic knowledge, i.e. \n",
    "\n",
    "$$\\text{Belief}[\\text{Cell}_i] = P(\\text{Target in Cell}_i|  \\text{Observations through time } t)$$ \n",
    "\n",
    "For every cell, this is the probability that a given cell contains the target given the existing knowledge base. Initially, as the agent has no prior knowledge about the map, the belief for each cell is $\\frac{1}{dim^2}$.\n",
    "\n",
    "Each cell also contains a terrain type which corresponds to the probability that a query will return a false negative, i.e.\n",
    "\n",
    "$$P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)$$\n",
    "\n",
    "which is $0.1$ for **flat** terrain cells, $0.3$ for **hilly** terrain cells, $0.7$ for **forested** terrain cells, and $0.9$ for cells whose terrain is a maze of **caves.**\n",
    "\n",
    "We assume that for any given map, each cell is assigned the flat terrain type with probability $0.2$, the hilly terrain type with probability $0.3$, the forested terrain type with probability $0.3$, and the caves terrain type with probability $0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landscape\n",
    "\n",
    "We implement the landscape as a class, which has the following fields:\n",
    "\n",
    "- `dim` (int): the dimension of the $dim$ by $dim$ map\n",
    "- `landscape` (2D list) of `landCell` objects, each of which tracks:\n",
    "    - `target` (int): `PRESENT = 1` if this cell is the target, or `ABSENT = 0` otherwise\n",
    "    - `terrain` (int): `FLAT = 0.1` if this cell has flat terrain, `HILLY = 0.3`, `FOREST = 0.7`, or `MAZE = 0.9`, etc.\n",
    "- `target_x` (int): the x-coordinate of the target cell\n",
    "- `target_y` (int): the y-coordinate of the target cell\n",
    "\n",
    "A landscape is initialized with non-target cells that are assigned terrain types based on the probabilities previously described. It then randomly selects one cell to be the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class landscape:\n",
    "\n",
    "    dim = 0\n",
    "    landscape = [[]]\n",
    "    target_x = 0\n",
    "    target_y = 0\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.landscape = [[landCell() for _ in range(self.dim)] for _ in range(self.dim)]\n",
    "\n",
    "        target_x = random.randint(0, dim - 1)\n",
    "        target_y = random.randint(0, dim - 1)\n",
    "        self.landscape[target_x][target_y].target = PRESENT\n",
    "        self.target_x = target_x\n",
    "        self.target_y = target_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Landscape.py`.\n",
    "\n",
    "The `landCell` object is also defined in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class landCell:\n",
    "\n",
    "    def __init__(self):\n",
    "        x = random.randint(1, 100)\n",
    "        self.target = ABSENT\n",
    "        if x <= 20:\n",
    "            self.terrain = FLAT\n",
    "        elif 20 < x <= 50:\n",
    "            self.terrain = HILLY\n",
    "        elif 50 < x <= 80:\n",
    "            self.terrain = FOREST\n",
    "        else:\n",
    "            self.terrain = MAZE\n",
    "\n",
    "    def getTerrain(self):\n",
    "        return self.terrain\n",
    "\n",
    "    def isTarget(self):\n",
    "        return (self.target==PRESENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Cell.py`.\n",
    "\n",
    "For example, an initialized $dim = 50$ landscape may look like this:\n",
    "\n",
    "![Blank Landscape](./imgs/landscape_blankTest.png)\n",
    "\n",
    "where the target is located at (40, 48)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the agent as a class, which has the following fields:\n",
    "\n",
    "- `knowledge` (2D list) of `agentCell` objects, each of which tracks:\n",
    "    - `belief` (float): the probability that a given cell contains the target, as described above; initially $1/{dim}^2$\n",
    "    - `status` (boolean): either `VISITED = True` or `UNVISITED = False` depending on whether or not the cell has been queried previously; initially `False`\n",
    "- `rule` (int): either 1 or 2, corresponding to the two probability rules described below\n",
    "- `num_actions` (int): the number of actions, whether queries or movements (in the later case of a movement-restricted agent), executed so far; initially 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent:\n",
    "    num_actions = 0\n",
    "\n",
    "    def __init__(self, landscape, rule):\n",
    "        self.ls = landscape\n",
    "        d = self.ls.dim\n",
    "\n",
    "        if rule == 1 or rule == 2:\n",
    "            self.rule = rule\n",
    "        else:\n",
    "            print(\"Invalid rule, set to 1 by default\")\n",
    "            self.rule = 1\n",
    "\n",
    "        self.knowledge = [[agentCell() for j in range(d)] for i in range(d)]\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                self.knowledge[i][j].setBelief(1/(d**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Agent.py`.\n",
    "\n",
    "The `agentCell` object is also defined in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agentCell:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.belief = 0\n",
    "        self.status = UNVISITED\n",
    "\n",
    "    def getBelief(self):\n",
    "        return self.belief\n",
    "\n",
    "    def getStatus(self):\n",
    "        return self.status\n",
    "\n",
    "    def setBelief(self,belief):\n",
    "        self.belief = belief\n",
    "\n",
    "    def setStatus(self,status):\n",
    "        self.status = status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Cell.py`.\n",
    "\n",
    "For example, an initialized agent knowledge base with $dim = 50$ landscape may look like this:\n",
    "\n",
    "![Blank Beliefs](./imgs/belief_blankTest.png)\n",
    "\n",
    "where each cell has initial belief $\\frac{1}{50^2} = 0.0004$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agent` class has the following methods:\n",
    "\n",
    "- `searchCell(cell)` (boolean): query a `landCell` object. If it is not the target, return `False`. If it is the target, then only return `True` with probability $p = 1 - P(\\text{false negative})$, where the false negative probability depends on that cell's terrain type as described previously. Otherwise, return `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchCell(self,cell): #search a landCell\n",
    "    if not cell.isTarget():\n",
    "        return False\n",
    "    else:\n",
    "        p = 1 - cell.getTerrain()\n",
    "        if random.uniform(0, 1) < p:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `getVisited()` (list): return a list of all (x,y) coordinates which the agent has already queried at a given point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVisited(self):\n",
    "    n = self.ls.dim\n",
    "    coords = []\n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            if self.knowledge[x][y].getStatus():\n",
    "                coords.append((x,y))\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the belief state\n",
    "\n",
    "We require a method to update the belief state given the results of a query. There are two cases: \n",
    "\n",
    "1. A query of a cell found the target, in which case the belief for this cell is set to 1, and the beliefs for all other cells are set to 0.\n",
    "\n",
    "2. A query of a cell did not find the target, in which case the belief for this cell must be adjusted considering the probability that the query returned a false negative.\n",
    "\n",
    "The latter case considers the probability \n",
    "\n",
    "$$P(\\text{Target in Cell}_i | \\text{Observations}_t \\land \\text{Failure in Cell}_j)$$\n",
    "\n",
    "and relies on the probabilistic knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $H := \\{\\text{Target in Cell}_i\\}$ and $E := \\{\\text{Target not found if we queried every cell}\\}$. \n",
    "\n",
    "Then we want $P(H|E)$, or the probability that the target is in a cell given we have not found the target in any of our queries. We would like to compute this upon a failed query of a cell and accept this quantity as that cell's new belief.\n",
    "\n",
    "By **Bayes' theorem,** this quantity is:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H)P(H)}{P(E)}$$\n",
    "\n",
    "Observe that $P(E|H)$ is the probability that the target is not found given the target is in the cell, which is exactly the false negative probability described above per terrain type. And $P(H)$ is exactly the agent's belief for that cell in the previous time step.\n",
    "\n",
    "One can see that observing a failed query for a given cell will decrease our belief that this cell contains the target, but this decrease is scaled by the possibility of false negatives.\n",
    "\n",
    "$P(E)$ is calculated with the following function: \n",
    "\n",
    "$$P(E) = \\sum_{i \\text{ visited}} P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i) + \\sum_{j \\text{ unvisited}} P(\\text{Target not in Cell}_j)$$\n",
    "\n",
    "That is, it is the probability that some queried cell was a false negative and that the unqueried cells do not contain the target. In this situation, querying all remaining cells would not lead to us finding the target.\n",
    "\n",
    "Finally, once a queried cell is updated, we must update the rest of the knowledge base. \n",
    "\n",
    "Let $R_i = |{\\text{new belief of Cell}_i} - {\\text{old belief of Cell}_i}|$, or the difference between the new and old beliefs of the queried cell.\n",
    "\n",
    "Then for all remaining cells $j$, use the following update formula: \n",
    "\n",
    "$$\\text{Belief}^{t+1}_j = \\text{Belief}^t_j + \\frac{\\text{Belief}^t_j * R_i}{1 - R_i}$$\n",
    "\n",
    "This, in a sense, scales the previous belief by how much our query impacted the belief of the queried cell. One can see how failed queries will increase the beliefs of all other cells per iteration, although this increase may be marginal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Based on the intuition above, the implementation of a belief update is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBelief(self,x,y):\n",
    "    if self.searchCell(self.ls.landscape[x][y]):\n",
    "        for i in range(self.ls.dim):\n",
    "            for j in range(self.ls.dim):\n",
    "                self.knowledge[i][j].setBelief(0)\n",
    "        self.knowledge[x][y].setBelief(1)\n",
    "    else:\n",
    "        #P(H|E) = P(E|H)P(H)/P(E)\n",
    "        #H: Target in cell\n",
    "        #E: Target not found\n",
    "        curr_belief = self.knowledge[x][y].getBelief()\n",
    "        num = self.ls.landscape[x][y].getTerrain()*curr_belief\n",
    "        denom = self.probNotFound()\n",
    "        remainder = abs(curr_belief - (num/denom))\n",
    "        self.knowledge[x][y].setBelief(num/denom)\n",
    "        for i in range(self.ls.dim):\n",
    "            for j in range(self.ls.dim):\n",
    "                if i == x and j == y:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp = self.knowledge[i][j].getBelief()\n",
    "                    self.knowledge[i][j].setBelief(temp + (temp*remainder)/(1-remainder))\n",
    "\n",
    "    return self.knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This relies on the function `probNotFound` which computes $P(H|E)$ above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probNotFound(self):\n",
    "    n = self.ls.dim\n",
    "    res = 0\n",
    "    coords = self.getVisited()\n",
    "    res = (n**2 - len(coords))/(n**2)\n",
    "    for coord in coords:\n",
    "        res += (self.ls.landscape[coord].getTerrain())*(self.knowledge[coord].getBelief())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more implementation details, see `Agent.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent search strategies\n",
    "\n",
    "Armed with this `updateBelief` function, we need to define how the agent will choose cells to query in order to search maps. We consider two rules for which cell the agent should query next:\n",
    "\n",
    "1. Query the cell with the highest belief, i.e. the probability that the target is in that cell\n",
    "\n",
    "2. Query the cell with the highest probability that the target will be found in such a query\n",
    "\n",
    "We implement both probability rules, and then use either of them to implement the agent's search algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 1: Probability that the target is in a given cell\n",
    "\n",
    "This is based on the same $P(H|E)$ computed above. Upon each failed query, we update the entire knowledge base of beliefs as described above, and then we visit the cell with the highest belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 2: Probability that the target will be found, if a given cell is searched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic intuition\n",
    "\n",
    "Observe that this probability is different from $\\text{Belief}_i$. It must consider the impact of the terrain's interference with queries, i.e. potential false negatives. We want the following probability:\n",
    "\n",
    "$$P(F) := P(\\text{Target found in Cell}_i | \\text{Observations}_t)$$\n",
    "\n",
    "which is equal to:\n",
    "\n",
    "$$(1 - P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)) * P(\\text{Target is in Cell}_i)$$\n",
    "\n",
    "Note that $P(\\text{Target is in Cell}_i)$ is exactly $P(H)$ from before, and $P(\\text{Target not found in Cell}_i | \\text{Target is in Cell}_i)$ is determined by the terrain type of $\\text{Cell}_i$, so we can easily compute $P(F)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The probability that the target will be found at a given cell if it is searched is computed by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probFound(self,x,y):\n",
    "        return (1-self.ls.landscape[x][y].getTerrain())*self.knowledge[x][y].getBelief()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison between rules 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted agent movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 3: Utility and decision-making strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison with unrestricted movement via rules 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A drunk man"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A moving target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider a target which is not static in that:\n",
    "\n",
    "1. Upon every failed query, the target moves to one of its neighbors at random.\n",
    "2. Upon moving to one of its neighbors, some sensor returns an observation of terrain type (\"FLAT\" , \"HILLY\", etc.). However, the sensor is broken, so it returns some type that the new target is **not,** at random. \n",
    "\n",
    "For example, if we query a cell and do not find the target, and we get the new observation \"HILLY\", then we know that the target is now in a cell which is either \"FLAT\", \"FOREST\", or \"MAZE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Due to the object-oriented nature of our `Landscape` class, the target can easily be moved.\n",
    "\n",
    "The below code moves the target to one of its neighbors at random, and returns a terrain type the new target is not, at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveTarget(self):\n",
    "    x = self.target_x; y = self.target_y\n",
    "    self.landscape[x][y].target = ABSENT\n",
    "\n",
    "    nbrs = []\n",
    "    for dx, dy in dirs:\n",
    "        if 0 <= x + dx < self.dim and 0 <= y + dy < self.dim:\n",
    "            nbrs.append((x + dx, y + dy))\n",
    "\n",
    "    new_nbr = random.choice(nbrs)\n",
    "    self.target_x = new_nbr[0]; self.target_y = new_nbr[1]\n",
    "    self.landscape[self.target_x][self.target_y].target = PRESENT\n",
    "\n",
    "    terrains = {FLAT, HILLY, FOREST, MAZE}\n",
    "    new_terrain = {(self.landscape[self.target_x][self.target_y]).terrain}\n",
    "    return random.choice(list(terrains.difference(new_terrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A moving target AND an agent with restricted movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
