{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorization\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Rohan Rele (rsr132)\n",
    "- Aakash Raman (abr103)\n",
    "- Alex Eng (ame136)\n",
    "- Adarsh Patel (aap237)\n",
    "\n",
    "This project was completed for Professor Wes Cowan's Fall 2019 offering of the CS 520: Intro to Artificial Intelligence course, taught at Rutgers University, New Brunswick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we tackle the problem of colorizing black-and-white photos. That is, given an input image for which every pixel only has one numerical value representing lightness, i.e. ranging from white to black, we seek to output an image for which every pixel has three numerical values corresponding to the Red, Green, and Blue (RGB) color channels. \n",
    "\n",
    "The challenge is that grayscale images contain less information than RGB images, so mapping from the former to the latter will certainly involve some perceptual and numerical loss in conversion. To identify this loss, we start with color images, convert them to grayscale, attempt to colorize them, and then compare the result with the original truth color images. In this way, we seek to solve a supervised machine learning problem wherein we attempt to predict the \"true\" coloring of an image when we know what that \"true\" coloring ought to be.\n",
    "\n",
    "To that end, we build and train a neural network to colorize a black-and-white photo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "## Color spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a **color image** with $n \\times m$ pixel dimensions. We consider its numerical representation as an $n \\times m \\times 3$ tensor, which can be thought of as an $n \\times m$ matrix for which each entry corresponds to one pixel and is a matrix with dimension $3 \\times 1$: one value for each of the R, G, and B channels to \"color\" that pixel.\n",
    "\n",
    "For example:\n",
    "\n",
    "$$I_{rgb} = \\begin{bmatrix} \n",
    "    \\begin{bmatrix} r_{0,0} & g_{0,0} & b_{0,0} \\end{bmatrix} &\n",
    "    \\begin{bmatrix} r_{0,1} & g_{0,1} & b_{0,1} \\end{bmatrix} &\n",
    "    \\dots \n",
    "    \\begin{bmatrix} r_{0,m} & g_{0,m} & b_{0,m} \\end{bmatrix} \\\\\n",
    "    {} & \\ddots & {} \\\\\n",
    "    \\begin{bmatrix} r_{1,0} & g_{1,0} & b_{1,0} \\end{bmatrix} &\n",
    "    \\begin{bmatrix} r_{1,1} & g_{1,1} & b_{1,1} \\end{bmatrix} &\n",
    "    \\dots \n",
    "    \\begin{bmatrix} r_{n,m} & g_{n,m} & b_{n,m} \\end{bmatrix}\n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "\n",
    "where $r_{i,j}, g_{i,j}, b_{i,j} \\in [0,255]$ each represent the $(i,j)$-th pixel's color along the red, green, and blue channels. The reader is likely familiar with the following two colors in RGB:\n",
    "\n",
    "$$(r=0, g=0, b=0) \\rightarrow \\text{black}$$\n",
    "$$(r=255, g=255, b=255) \\rightarrow \\text{white}$$\n",
    "\n",
    "\n",
    "That being said, a **grayscale image** of the same pixel dimensions can intuitively be thought of as an $n \\times m \\times 1$ tensor, since each pixel can only contain one value for its lightness.\n",
    "\n",
    "For example:\n",
    "\n",
    "$$I_{gray} = \\begin{bmatrix}\n",
    "        p_{0,0} & p_{0,1} & \\dots \\ p_{0,m} \\\\\n",
    "        {} & \\ddots & {} \\\\\n",
    "        p_{n,0} & p_{n,1} & \\dots \\ p_{n,m}\n",
    "        \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "where $p_{i,j} \\in [0,255]$ represents the $(i,j)$-th pixel's lightness. For example, we have:\n",
    "\n",
    "$$(p=0) \\rightarrow \\text{black}$$\n",
    "$$(p=255) \\rightarrow \\text{white}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true
   },
   "source": [
    "## Color mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, for this problem, we can define our desired color mappings more rigorously than just saying \"go from black and white to color.\"\n",
    "\n",
    "We begin with an image with its true coloring, and map it to its RGB tensor form. Then, our neural network will attempt to predict the color values of the image based only on its grayscale information. Using the language of our color spaces, the neural network will predict a 3-tuple of R, G, and B channel values per pixel based off each pixel's inputted grayscale channel value. This process will be described at length later. Then, the resulting matrix will be parsed and saved as an image.\n",
    "\n",
    "In summary, our image conversion process can be represented as a sequence of functions mapping between the aforementioned color spaces as follows:\n",
    "\n",
    "$$\\text{Image} \\rightarrow I_{rgb} \\rightarrow I_{gray} \\xrightarrow{NN} I^{*}_{rgb} \\rightarrow \\text{Image}^{*}$$\n",
    "\n",
    "where the $LHS$ prior to the neural network are simple image conversions, the middle function is a lengthy composition of neural network operations, and the $RHS$ afterwards are also simple image conversions to recover the predicted colorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is a volume of multiple color images. \n",
    "\n",
    "    <!- add information about what the images are: nature, animals etc and how many images -!>\n",
    "\n",
    "To modify the above mappings to work on a volume of multiple images, we consider 4D tensors of dimensions $i, j, k, l$ where $i$ is the index of a given image in the list of input images, $j$ is the dimensionality of pixel information (i.e. 3 for RGB images), $k$ is the length of the image, and $l$ is the width of the image. Then, we may pass this entire 4D tensor through our network to encode the information of all images in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Given a 4D input tensor $T_{imgs}$, we carry out the $LHS$ of the color mapping sequence described above to pre-process each image in the input volume. The necessary vectorizations and color map conversions are accomplished in Python using the package `PIL` for image file parsing and `numpy` for image tensor operations.\n",
    "\n",
    "    <!- add some code for pre-processing -!>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN architecture can be described by the diagram below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical error: loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following loss function to determine the error of a certain pixel's coloring:\n",
    "\n",
    "$$Loss_t = \\sum_{P_{i,j}} (r^{I'}_{i,j} - r^{I_t}_{i,j})^2 + (g^{I'}_{i,j} - g^{I_t}_{i,j})^2 + (b^{I'}_{i,j} - b^{I_t}_{i,j})^2$$\n",
    "\n",
    "for pixel $P_{i,j}$ where $r^{I'}_{i,j}, g^{I'}_{i,j}$, and $b^{I'}_{i,j}$ are this pixel's true coloring, and $r^{I_t}_{i,j}, g^{I_t}_{i,j}$, and $b^{I_t}_{i,j}$ are this pixel's coloring in the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorization errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brand new input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
